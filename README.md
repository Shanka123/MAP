# This repository contains code for the paper titled "A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models"

## Requirements
- python 3.9.17
- numpy==1.24.3
- tqdm==4.65.0
- json==2.0.9
- openai==0.27.7

## Tower of Hanoi (ToH)


For ToH task, the codebase (inside `toh` directory) contains files to run LLM-PFC and GPT-4 baselines such as zero-shot, in-context learning (ICL), chain-of-thought (CoT ICL), and multi-agent debate (MAD). It also contains files to evaluate the outputs generated by the model runs.  

To run the above models you need to specify two required arguments- 1) openAI API key 2) directory name where output log files will be stored

For example to run and evaluate LLM-PFC first execute, `python gpt4_llmpfc_toh.py --openai_api_key '<YOUR OPENAI KEY>' --output_dir '<OUTPUT DIRECTORY NAME>'`

Then execute, `python gpt4_llmpfc_toh_eval.py --output_dir '<OUTPUT DIRECTORY NAME>'`



To run and evaluate one of the baseline models, for example, GPT-4 ICL first execute, `python gpt4_icl_toh.py --openai_api_key '<YOUR OPENAI KEY>' --output_dir '<OUTPUT DIRECTORY NAME>'`

Then execute, `python gpt4_icl_toh_eval.py --output_dir '<OUTPUT DIRECTORY NAME>'`

## Cogeval

For the Cogeval tasks (Valuepath, Steppath, Reward Revaluation, and Detour), the codebase (inside `cogeval` directory) contains files to run LLM-PFC and GPT-4 baselines such as zero-shot, in-context learning (ICL). It also contains files to evaluate the outputs generated by the model runs.  

To run the above models you need to specify two required arguments- 1) openAI API key 2) directory name where output log files will be stored

For example to run and evaluate LLM-PFC on the Valuepath task first execute, `python gpt4_llmpfc_valuepath.py --openai_api_key '<YOUR OPENAI KEY>' --output_dir '<OUTPUT DIRECTORY NAME>'`

Then execute, `python gpt4_llmpfc_valuepath_eval.py --output_dir '<OUTPUT DIRECTORY NAME>'`

To run and evaluate one of the baseline models, for example, GPT-4 ICL on the Valuepath task first execute, `python gpt4_standard_icl_valuepath.py --openai_api_key '<YOUR OPENAI KEY>' --output_dir '<OUTPUT DIRECTORY NAME>'`

Then execute, `python gpt4_valuepath_baselines_eval.py --output_dir '<OUTPUT DIRECTORY NAME>'`



## Logistics

For the Logistics task, the codebase (inside `logistics` directory) contains files to run LLM-PFC and GPT-4 baselines such as zero-shot, in-context learning (ICL). It also contains files to generate plan responses JSON for further evaluation.  

First clone the LLMs-Planning repo from https://github.com/karthikv792/LLMs-Planning, and the follow the instructions given in https://github.com/karthikv792/LLMs-Planning/tree/main/plan-bench for setup.

To run the above models you need to specify two required arguments- 1) openAI API key 2) directory name where output log files will be stored

For example to run LLM-PFC first execute, `python gpt4_llmpfc_plan_generation.py --openai_api_key '<YOUR OPENAI KEY>' --output_dir '<OUTPUT DIRECTORY NAME>'`


Then to generate the plan response JSON execute, `python gpt4_llmpfc_genplan_response_json.py --output_dir '<OUTPUT DIRECTORY NAME>'`

Finally, to evaluate the plan response JSON, execute `python LLMs-Planning/plan-bench/response_evaluation.py --task 't1' --config 'logistics' --engine 'llmpfc' --ignore_existing --verbose 'True'`


To run one of the baseline models, for example, GPT-4 ICL first execute, `python gpt4_icl_plan_generation.py --openai_api_key '<YOUR OPENAI KEY>' --output_dir '<OUTPUT DIRECTORY NAME>'`

Then to generate the plan response JSON execute, `python gpt4_baselines_genplan_response_json.py --output_dir '<OUTPUT DIRECTORY NAME>' --model 'gpt4_icl'`

Finally, to evaluate the plan response JSON, execute `python LLMs-Planning/plan-bench/response_evaluation.py --task 't1' --config 'logistics' --engine 'gpt4_icl' --ignore_existing --verbose 'True'`


